{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pomegranate quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this document, we apply the loopy belief propagation algorithm of pomegranate to a simple example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 07 2020 \n",
      "\n",
      "pomegranate 0.12.2\n",
      "\n",
      "compiler   : Clang 6.0 (clang-600.0.57)\n",
      "system     : Darwin\n",
      "release    : 19.0.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 12\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "from pomegranate import *\n",
    "%load_ext watermark\n",
    "%watermark -m -n -p pomegranate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the probablistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our example model is represented by this Bayesian network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/opengm_quickstart_bn.png\" width=\"200\" height=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, this graph indicates that the distribution factorizes as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/opengm_quickstart_factorization.png\" width = \"600\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the Bayesian network in pomegranate, we first create the distributions which live in each node in the graph. For a discrete (aka categorical) bayesian network we use `DiscreteDistribution` objects for the root nodes and `ConditionalProbabilityTable` objects for the inner and leaf nodes. The columns in a `ConditionalProbabilityTable` correspond to the order in which the parents (the second argument) are specified, and the last column is the value the `ConditionalProbabilityTable` itself takes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = DiscreteDistribution({'0':0.3, '1':0.7})\n",
    "\n",
    "X1 = ConditionalProbabilityTable(\n",
    "    [['0', '0', 0.2], \n",
    "     ['0' , '1', 0.8], \n",
    "     ['1', '0', 0.7], \n",
    "     ['1', '1', 0.3]], [X0])\n",
    "\n",
    "X2 = ConditionalProbabilityTable(\n",
    "    [['0', '0', 0.4], \n",
    "     ['0' , '1', 0.6], \n",
    "     ['1', '0', 0.3], \n",
    "     ['1', '1', 0.7]], [X0])\n",
    "\n",
    "X3 = ConditionalProbabilityTable(\n",
    "    [['0', '0','0', 0.2], \n",
    "     ['0', '0','1', 0.8], \n",
    "     ['0', '1','0', 0.3], \n",
    "     ['0', '1','1', 0.7], \n",
    "     ['1', '0','0', 0.6], \n",
    "     ['1', '0','1', 0.4], \n",
    "     ['1', '1','0', 0.7], \n",
    "     ['1', '1','1', 0.3]], [X1, X2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we pass these distributions into state objects along with the name for the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State objects hold both the distribution, and a high level name.\n",
    "s0 = State(X0, name=\"X0\")\n",
    "s1 = State(X1, name=\"X1\")\n",
    "s2 = State(X2, name=\"X2\")\n",
    "s3 = State(X3, name='X3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we add the states to the network. The way the states are added to the network makes no difference to it, and so you should add the states according to how the columns are organized in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bayesian network object with a useful name\n",
    "model = BayesianNetwork(\"Quick-Start\")\n",
    "\n",
    "# Add the three states to the network \n",
    "model.add_states(s0, s1, s2, s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to add edges to the model. The edges represent which states are parents of which other states. This is currently a bit redundant with passing in the distribution objects that are parents for each ConditionalProbabilityTable. Edges are added from parent -> child by calling model.add_edge(parent, child)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add edges which represent conditional dependencies, where the second node is \n",
    "# conditionally dependent on the first node (Monty is dependent on both guest and prize)\n",
    "model.add_edge(s0, s1)\n",
    "model.add_edge(s0, s2)\n",
    "model.add_edge(s1, s3)\n",
    "model.add_edge(s2, s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the model must be baked to finalize the internals. Since Bayesian networks use factor graphs for inference, an explicit factor graph is produced from the Bayesian network during the bake step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***model.predict_proba({})***\n",
    "\n",
    "Bayesian networks are explicitly turned into Factor Graphs when inference is done, wherein the Bayesian network is turned into a bipartite graph with all variables having marginal nodes on one side, and joint tables on the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomegranate uses the loopy belief propagation algorithm to do inference. This is an approximate algorithm which can yield exact results in tree-like graphs, and in most other cases still yields good results. Inference on a Bayesian network consists of taking in observations for a subset of the variables and using that to infer the values that the other variables take. The most variables which are observed, the closer the inferred values will be to truth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run inference using the `predict_proba` method and passing in a dictionary of values, where the key is the name of the state and the value is the observed value for that state. If we don't supply any values, we get the marginal of the graph, which is just the frequency of each value for each variable over an infinite number of randomly drawn samples from the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what happens when we look at the marginal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{\n",
       "    \"class\" :\"Distribution\",\n",
       "    \"dtype\" :\"str\",\n",
       "    \"name\" :\"DiscreteDistribution\",\n",
       "    \"parameters\" :[\n",
       "        {\n",
       "            \"0\" :0.3000000000000003,\n",
       "            \"1\" :0.6999999999999995\n",
       "        }\n",
       "    ],\n",
       "    \"frozen\" :false\n",
       "},\n",
       "       {\n",
       "    \"class\" :\"Distribution\",\n",
       "    \"dtype\" :\"str\",\n",
       "    \"name\" :\"DiscreteDistribution\",\n",
       "    \"parameters\" :[\n",
       "        {\n",
       "            \"1\" :0.4500000000000003,\n",
       "            \"0\" :0.5499999999999997\n",
       "        }\n",
       "    ],\n",
       "    \"frozen\" :false\n",
       "},\n",
       "       {\n",
       "    \"class\" :\"Distribution\",\n",
       "    \"dtype\" :\"str\",\n",
       "    \"name\" :\"DiscreteDistribution\",\n",
       "    \"parameters\" :[\n",
       "        {\n",
       "            \"1\" :0.6699999999999997,\n",
       "            \"0\" :0.3300000000000002\n",
       "        }\n",
       "    ],\n",
       "    \"frozen\" :false\n",
       "},\n",
       "       {\n",
       "    \"class\" :\"Distribution\",\n",
       "    \"dtype\" :\"str\",\n",
       "    \"name\" :\"DiscreteDistribution\",\n",
       "    \"parameters\" :[\n",
       "        {\n",
       "            \"1\" :0.5529999999999999,\n",
       "            \"0\" :0.4470000000000001\n",
       "        }\n",
       "    ],\n",
       "    \"frozen\" :false\n",
       "}], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are returned three `DiscreteDistribution` objects, each representing the marginal distribution for each variable, in the same order they were put into the model. In this case, they represent the guest, prize, and monty variables respectively. We see that everything is equally likely.\n",
    "\n",
    "We can also pass in an array where `None` (or `np.nan`) correspond to the unobserved values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([{\n",
       "     \"class\" :\"Distribution\",\n",
       "     \"dtype\" :\"str\",\n",
       "     \"name\" :\"DiscreteDistribution\",\n",
       "     \"parameters\" :[\n",
       "         {\n",
       "             \"0\" :0.3000000000000003,\n",
       "             \"1\" :0.6999999999999995\n",
       "         }\n",
       "     ],\n",
       "     \"frozen\" :false\n",
       " },\n",
       "        {\n",
       "     \"class\" :\"Distribution\",\n",
       "     \"dtype\" :\"str\",\n",
       "     \"name\" :\"DiscreteDistribution\",\n",
       "     \"parameters\" :[\n",
       "         {\n",
       "             \"1\" :0.4500000000000003,\n",
       "             \"0\" :0.5499999999999997\n",
       "         }\n",
       "     ],\n",
       "     \"frozen\" :false\n",
       " },\n",
       "        {\n",
       "     \"class\" :\"Distribution\",\n",
       "     \"dtype\" :\"str\",\n",
       "     \"name\" :\"DiscreteDistribution\",\n",
       "     \"parameters\" :[\n",
       "         {\n",
       "             \"1\" :0.6699999999999997,\n",
       "             \"0\" :0.3300000000000002\n",
       "         }\n",
       "     ],\n",
       "     \"frozen\" :false\n",
       " },\n",
       "        {\n",
       "     \"class\" :\"Distribution\",\n",
       "     \"dtype\" :\"str\",\n",
       "     \"name\" :\"DiscreteDistribution\",\n",
       "     \"parameters\" :[\n",
       "         {\n",
       "             \"1\" :0.5529999999999999,\n",
       "             \"0\" :0.4470000000000001\n",
       "         }\n",
       "     ],\n",
       "     \"frozen\" :false\n",
       " }], dtype=object)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([[None, None, None, None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the variables that were observed will be the observed value, and all of the variables that were unobserved will be a `DiscreteDistribution` object. This means that `parameters[0]` will return the underlying dictionary used by the distribution.\n",
    "\n",
    "Let us now set the evidence X3 = 1 and calculate the marginals of other variables subject to this evidence. We do this by passing a dictionary to `predict_proba` with key pairs consisting of the name of the state (in the state object), and the value which that variable has taken, or by passing in a list where the first index is our observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([{\n",
       "     \"class\" :\"Distribution\",\n",
       "     \"dtype\" :\"str\",\n",
       "     \"name\" :\"DiscreteDistribution\",\n",
       "     \"parameters\" :[\n",
       "         {\n",
       "             \"0\" :0.2270974567747094,\n",
       "             \"1\" :0.7729025432252905\n",
       "         }\n",
       "     ],\n",
       "     \"frozen\" :false\n",
       " },\n",
       "        {\n",
       "     \"class\" :\"Distribution\",\n",
       "     \"dtype\" :\"str\",\n",
       "     \"name\" :\"DiscreteDistribution\",\n",
       "     \"parameters\" :[\n",
       "         {\n",
       "             \"1\" :0.27224877455749763,\n",
       "             \"0\" :0.7277512254425024\n",
       "         }\n",
       "     ],\n",
       "     \"frozen\" :false\n",
       " },\n",
       "        {\n",
       "     \"class\" :\"Distribution\",\n",
       "     \"dtype\" :\"str\",\n",
       "     \"name\" :\"DiscreteDistribution\",\n",
       "     \"parameters\" :[\n",
       "         {\n",
       "             \"1\" :0.6379925816574398,\n",
       "             \"0\" :0.3620074183425603\n",
       "         }\n",
       "     ],\n",
       "     \"frozen\" :false\n",
       " },\n",
       "        '1'], dtype=object)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([{\"X3\":\"1\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the inference step is performed, we can get the marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'0': 0.2270974567747094, '1': 0.7729025432252905}]\n",
      "[{'1': 0.27224877455749763, '0': 0.7277512254425024}]\n",
      "[{'1': 0.6379925816574398, '0': 0.3620074183425603}]\n"
     ]
    }
   ],
   "source": [
    "x = model.predict_proba([{\"X3\":\"1\"}])\n",
    "for i in range(len(x[0])-1):\n",
    "    print(x[0][i].parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***model.predict()***\n",
    "\n",
    "This method returns the most likely component for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['1', '0', '1', '1'], dtype=object)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([{}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
